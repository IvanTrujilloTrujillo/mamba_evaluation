{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, MambaForCausalLM\n",
    "from datasets import load_dataset\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Trelis/tiny-shakespeare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (472, 1), 'test': (49, 1)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Text'],\n",
       "    num_rows: 472\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"TRANIO:\\nIs this your speeding? nay, then, good night our part!\\n\\nPETRUCHIO:\\nBe patient, gentlemen; I choose her for myself:\\nIf she and I be pleased, what's that to you?\\n'Tis bargain'd 'twixt us twain, being alone,\\nThat she shall still be curst in company.\\nI tell you, 'tis incredible to believe\\nHow much she loves me: O, the kindest Kate!\\nShe hung about my neck; and kiss on kiss\\nShe vied so fast, protesting oath on oath,\\nThat in a twink she won me to her love.\\nO, you are novices! 'tis a world to see,\\nHow tame, when men and women are alone,\\nA meacock wretch can make the curstest shrew.\\nGive me thy hand, Kate: I will unto Venice,\\nTo buy apparel 'gainst the wedding-day.\\nProvide the feast, father, and bid the guests;\\nI will be sure my Katharina shall be fine.\\n\\nBAPTISTA:\\nI know not what to say: but give me your hands;\\nGod send you joy, Petruchio! 'tis a match.\\n\\nGREMIO:\\nAmen, say we: we will be witnesses.\\n\\nPETRUCHIO:\\nFather, and wife, and gentlemen, adieu;\\nI will to Venice; Sunday comes apace:\\nWe will have rings and things and fine array;\\nAnd kiss me, Kate, we will be married o'Sunday.\\n\\nGREMIO:\\nWas ever match clapp'd up so suddenly?\\n\\nBAPTISTA:\\nFaith, gentlemen, now I play a merchant's part,\\nAnd venture madly on a desperate mart.\\n\\nTRANIO:\\n'Twas a commodity lay fretting by you:\\n'Twill bring you gain, or perish on the seas.\\n\\nBAPTISTA:\\nThe gain I seek is, quiet in the match.\\n\\nGREMIO:\\nNo doubt but he hath got a quiet catch.\\nBut now, Baptists, to your younger daughter:\\nNow is the day we long have looked for:\\nI am your neighbour, and was suitor first.\\n\\nTRANIO:\\nAnd I am one that love Bianca more\\nThan words can witness, or your thoughts can guess.\\n\\nGREMIO:\\nYoungling, thou canst not love so dear as I.\\n\\nTRANIO:\\nGraybeard, thy love doth freeze.\\n\\nGREMIO:\\nBut thine doth fry.\\nSkipper, stand back: 'tis age that nourisheth.\\n\\nTRANIO:\\nBut youth in ladies' eyes that flourisheth.\\n\\nBAPTISTA:\\nContent you, gentlemen: I will compound this strife:\\n'Tis deeds must win the prize; and he of both\\nThat can assure my daughter greatest dower\\nShall have my Bianca's love.\\nSay, Signior Gremio, What can you assure her?\\n\\nGREMIO:\\nFirst, as you know, my house within the city\\nIs richly furnished with plate and gold;\\nBasins and ewers to lave her dainty hands;\\nMy hangings all of Tyrian tapestry;\\nIn ivory coffers I have stuff'd my crowns;\\nIn cypress chests my arras counterpoints,\\nCostly apparel, tents, and canopies,\\nFine linen, Turkey cushions boss'd with pearl,\\nValance of Venice gold in needlework,\\nPewter and brass and all things that belong\\nTo house or housekeeping: then, at my farm\\nI have a hundred milch-kine to the pail,\\nSixscore fat oxen standing in my stalls,\\nAnd all things answerable to this portion.\\nMyself am struck in years, I must confess;\\nAnd if I die to-morrow, this is hers,\\nIf whilst I live she will be only mine.\\n\\nTRANIO:\\nThat 'only' came well in.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"][\"Text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2859"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[\"test\"][\"Text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = \"130m\"\n",
    "# model_size = \"370m\"\n",
    "# model_size = \"790m\"\n",
    "# model_size = \"1.4b\"\n",
    "# model_size = \"2.8b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n"
     ]
    }
   ],
   "source": [
    "model = MambaForCausalLM.from_pretrained(f\"state-spaces/mamba-{model_size}-hf\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341a843ca9294df6a821e8d131757b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/4.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a5b4f6dd4041938e1696155ed47245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(f\"state-spaces/mamba-{model_size}-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itrujillo/.local/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'architectures': ['MambaForCausalLM'],\n",
       "  'bos_token_id': 0,\n",
       "  'conv_kernel': 4,\n",
       "  'd_inner': 1536,\n",
       "  'd_model': 768,\n",
       "  'eos_token_id': 0,\n",
       "  'expand': 2,\n",
       "  'fused_add_norm': True,\n",
       "  'hidden_act': 'silu',\n",
       "  'hidden_size': 768,\n",
       "  'initializer_range': 0.1,\n",
       "  'intermediate_size': 1536,\n",
       "  'layer_norm_epsilon': 1e-05,\n",
       "  'model_type': 'mamba',\n",
       "  'n_layer': 24,\n",
       "  'num_hidden_layers': 24,\n",
       "  'pad_token_id': 0,\n",
       "  'pad_vocab_size_multiple': 8,\n",
       "  'rescale_prenorm_residual': False,\n",
       "  'residual_in_fp32': True,\n",
       "  'rms_norm': True,\n",
       "  'ssm_cfg': {},\n",
       "  'state_size': 16,\n",
       "  'time_step_floor': 0.0001,\n",
       "  'time_step_init_scheme': 'random',\n",
       "  'time_step_max': 0.1,\n",
       "  'time_step_min': 0.001,\n",
       "  'time_step_rank': 48,\n",
       "  'time_step_scale': 1.0,\n",
       "  'torch_dtype': 'float32',\n",
       "  'transformers_version': '4.39.0.dev0',\n",
       "  'use_bias': False,\n",
       "  'use_cache': True,\n",
       "  'use_conv_bias': True,\n",
       "  'vocab_size': 50280,\n",
       "  '_commit_hash': '1e76775f628fbf1350fbe4dbb3d971ba64af25a1'},\n",
       " {})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.get_config_dict(f\"state-spaces/mamba-{model_size}-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = load(\"perplexity\", module_type=\"metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for text in dataset[\"test\"][\"Text\"]:\n",
    "        encodings = tokenizer(text, return_tensors= \"pt\", padding=True)\n",
    "        input_ids = encodings.input_ids.to(device)\n",
    "        outputs = model(input_ids)\n",
    "        p = tokenizer.decode(outputs.logits.argmax(dim=-1)[0], skip_special_tokens=True)\n",
    "        predictions.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"TRANIO:\\nIs this your speeding? nay, then, good night our part!\\n\\nPETRUCHIO:\\nBe patient, gentlemen; I choose her for myself:\\nIf she and I be pleased, what's that to you?\\n'Tis bargain'd 'twixt us twain, being alone,\\nThat she shall still be curst in company.\\nI tell you, 'tis incredible to believe\\nHow much she loves me: O, the kindest Kate!\\nShe hung about my neck; and kiss on kiss\\nShe vied so fast, protesting oath on oath,\\nThat in a twink she won me to her love.\\nO, you are novices! 'tis a world to see,\\nHow tame, when men and women are alone,\\nA meacock wretch can make the curstest shrew.\\nGive me thy hand, Kate: I will unto Venice,\\nTo buy apparel 'gainst the wedding-day.\\nProvide the feast, father, and bid the guests;\\nI will be sure my Katharina shall be fine.\\n\\nBAPTISTA:\\nI know not what to say: but give me your hands;\\nGod send you joy, Petruchio! 'tis a match.\\n\\nGREMIO:\\nAmen, say we: we will be witnesses.\\n\\nPETRUCHIO:\\nFather, and wife, and gentlemen, adieu;\\nI will to Venice; Sunday comes apace:\\nWe will have rings and things and fine array;\\nAnd kiss me, Kate, we will be married o'Sunday.\\n\\nGREMIO:\\nWas ever match clapp'd up so suddenly?\\n\\nBAPTISTA:\\nFaith, gentlemen, now I play a merchant's part,\\nAnd venture madly on a desperate mart.\\n\\nTRANIO:\\n'Twas a commodity lay fretting by you:\\n'Twill bring you gain, or perish on the seas.\\n\\nBAPTISTA:\\nThe gain I seek is, quiet in the match.\\n\\nGREMIO:\\nNo doubt but he hath got a quiet catch.\\nBut now, Baptists, to your younger daughter:\\nNow is the day we long have looked for:\\nI am your neighbour, and was suitor first.\\n\\nTRANIO:\\nAnd I am one that love Bianca more\\nThan words can witness, or your thoughts can guess.\\n\\nGREMIO:\\nYoungling, thou canst not love so dear as I.\\n\\nTRANIO:\\nGraybeard, thy love doth freeze.\\n\\nGREMIO:\\nBut thine doth fry.\\nSkipper, stand back: 'tis age that nourisheth.\\n\\nTRANIO:\\nBut youth in ladies' eyes that flourisheth.\\n\\nBAPTISTA:\\nContent you, gentlemen: I will compound this strife:\\n'Tis deeds must win the prize; and he of both\\nThat can assure my daughter greatest dower\\nShall have my Bianca's love.\\nSay, Signior Gremio, What can you assure her?\\n\\nGREMIO:\\nFirst, as you know, my house within the city\\nIs richly furnished with plate and gold;\\nBasins and ewers to lave her dainty hands;\\nMy hangings all of Tyrian tapestry;\\nIn ivory coffers I have stuff'd my crowns;\\nIn cypress chests my arras counterpoints,\\nCostly apparel, tents, and canopies,\\nFine linen, Turkey cushions boss'd with pearl,\\nValance of Venice gold in needlework,\\nPewter and brass and all things that belong\\nTo house or housekeeping: then, at my farm\\nI have a hundred milch-kine to the pail,\\nSixscore fat oxen standing in my stalls,\\nAnd all things answerable to this portion.\\nMyself am struck in years, I must confess;\\nAnd if I die to-morrow, this is hers,\\nIf whilst I live she will be only mine.\\n\\nTRANIO:\\nThat 'only' came well in.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"][\"Text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SP, I\\n it a first ticket\\nah, your,\\n,,\\ning\\n\\n_ERCHIO:\\nIhold, my, I am to. you.\\nI she be I are friends, I will the to you?\\n\\nTis a,,twillxt us,ain, and so.\\nAnd we shall be be mysing, her.\\n\\n'll you, mytis not, me\\nThat much she is you, and, I moreest,!\\n\\n's upon my neck, and,'d kiss,I kissedied with with with that,, oath,\\nThat I her momentinklingly would't to her side.\\n\\n, my are aices, youT a thing of be\\n\\nAnd much and how you are women are so,\\nAndrenekke ofring,'t, worldst fool kiss.\\n\\n me your hand, and, I'll not thee.\\nAnd Venice herarel fortwst the world ofday.\\n\\nide me best, and, and let me maid\\n\\nAnd'll not thy to lovearineina will be\\n.\\n\\nPETENTISTE:\\nI will not what to say,\\n I me your hand,\\nAnd be me a, andruchio!\\ntis a joy\\n\\n\\nPETAT::\\nI thousand, my,, and are be merry.\\n\\nPETRUCHIO:\\nI, I mother, and children,\\nieu!\\nI will be Venice, and,.ace.\\nI will be a, flowers to a things,\\nAnd, the, and, and will kiss friends.'er.\\n\\nPETMIO:\\nI it so soapped'd in so fast?\\n\\nPETAPTISTA:\\nIith, I, I we know the trick. game.\\nAnd I toly to the new voyageyr\\n\\nPETIO:\\nITis a match, inted in the,\\nAndTis be you to, and loseish by the sea.\\n\\nPETAPTISTA:\\n' world is will, to toness my night.\\n\\nGREMIO:\\n',, you will a it wife match.\\n\\n,, Kateista, I the part days.\\nI, the time for shall to waited for.\\nWe will ready wife, and I youring..\\n\\nPETIO:\\n' now, your of hath youca. thanThan you can say. or love love. tell.\\n\\nBMIO:\\nI Kate, you artst not be me much. I.\\n\\nBIO:\\nI,ard, thou love isoth not me\\n\\nBMIO:\\nI,ine,oth not,\\n\\naidpper, thou by, Itis a, makesishesheth\\n\\n\\nBIO:\\nI,, love, hands, loveishesheth\\n\\n\\nGREAPTISTA:\\n',, Kate, I will not\\n.ife.\\nITis a that be, love. and I that whom\\nShall hath not me love's loveower.Is be her loveca's love.\\n\\n, whator,avio, what is I say??\\n\\nBMIO:\\nI, that I have, I dear is the walls\\nIs thely furnished, the and wine.\\nAndil and ciswers, serveve the,owerty feet,\\nAnd chamberings and of goldre goldestry,\\nAnd theory anders and have as my chamberns;\\nAnd goldpress andsts and coffas;feit;\\nAndume asarel, and, and otheropies,\\nAnd and, and,ions,ed with goldls,\\nAndu, gold,, goldwork,\\nAndaintedter, gold, copper, of are\\nTo the and to-, and, my my door,I have a house thousandle cowscine, feed dayonies,\\nAnd hundred to pigsen to in the yard,\\nAnd a the that to for my house.\\n\\nineelf, a with the, and am be,\\nBut I I had,-morrow, I will my to\\nAnd I I live, shall be mine a.\\n\\nGREIO:\\nI'ss, is from to my\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd43af851e54b3387130c9f7c51f32c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = perplexity.compute(predictions=predictions, model_id='gpt2', add_start_token=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'perplexities': [221.55735778808594,\n",
       "  198.0741424560547,\n",
       "  217.16162109375,\n",
       "  228.64495849609375,\n",
       "  120.38847351074219,\n",
       "  261.9655456542969,\n",
       "  227.4635467529297,\n",
       "  161.25106811523438,\n",
       "  217.4535369873047,\n",
       "  121.30035400390625,\n",
       "  206.34690856933594,\n",
       "  242.25991821289062,\n",
       "  210.80319213867188,\n",
       "  194.0653839111328,\n",
       "  227.86109924316406,\n",
       "  151.5801239013672,\n",
       "  176.01309204101562,\n",
       "  236.51327514648438,\n",
       "  151.68605041503906,\n",
       "  174.5030059814453,\n",
       "  273.3298034667969,\n",
       "  130.21368408203125,\n",
       "  98.06568908691406,\n",
       "  256.57977294921875,\n",
       "  223.55010986328125,\n",
       "  185.99839782714844,\n",
       "  134.82040405273438,\n",
       "  148.70501708984375,\n",
       "  148.43099975585938,\n",
       "  116.62020874023438,\n",
       "  215.33444213867188,\n",
       "  86.23014831542969,\n",
       "  226.6719512939453,\n",
       "  214.08407592773438,\n",
       "  322.2111511230469,\n",
       "  241.0570068359375,\n",
       "  184.97647094726562,\n",
       "  251.6980438232422,\n",
       "  356.30267333984375,\n",
       "  260.2293701171875,\n",
       "  424.2401428222656,\n",
       "  325.1575622558594,\n",
       "  312.4330139160156,\n",
       "  295.7098693847656,\n",
       "  373.6962585449219,\n",
       "  84.69954681396484,\n",
       "  94.79121398925781,\n",
       "  229.6900634765625,\n",
       "  141.32553100585938],\n",
       " 'mean_perplexity': 210.28051586540377}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados perplexity:\n",
    "\n",
    "· Trelis/tiny-shakespeare (test):\n",
    "\n",
    "    130m -> 210.281 points\n",
    "    370m -> 211.817 points\n",
    "    790m -> 215.818 points\n",
    "    1.4b -> 214.880 points\n",
    "    2.8b -> 196.647 points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
